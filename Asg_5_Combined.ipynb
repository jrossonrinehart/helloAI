{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ic9ORAnKDtV",
        "outputId": "706fed4f-2139-4287-be41-428488edc656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nn3/src\n"
          ]
        }
      ],
      "source": [
        "#!git clone \"https://github.com/kartoone/nn3\"\n",
        "#!cat nn3/keras.json > ~/.keras/keras.json\n",
        "#!pip install theano\n",
        "%cd nn3/src"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 1"
      ],
      "metadata": {
        "id": "mqVa2yuT4WsC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "not sure if this first network below was supposed to actually run or just to test that it works. I only ran the 2nd network below to 99.25 accuracy"
      ],
      "metadata": {
        "id": "geO0TJ2D-FbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import network3\n",
        "from network3 import Network\n",
        "from network3 import ConvPoolLayer, FullyConnectedLayer, SoftmaxLayer\n",
        "training_data, validation_data, test_data = network3.load_data_shared()\n",
        "mini_batch_size = 10\n",
        "\n",
        "start = time.time()\n",
        "net = Network([\n",
        "        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
        "                      filter_shape=(20, 1, 5, 5), \n",
        "                      poolsize=(2, 2)),\n",
        "        FullyConnectedLayer(n_in=20*12*12, n_out=100),\n",
        "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
        "net.SGD(training_data, 60, mini_batch_size, 0.1, \n",
        "            validation_data, test_data)   \n",
        "finish = time.time()\n",
        "elapsed = finish-start\n",
        "print(elapsed)"
      ],
      "metadata": {
        "id": "co6yvKlYK1w_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "758bc9e0-ee66-4b4e-d9f8-4dc428d6ff9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying to run under a GPU.  If this is not desired, then modify network3.py\n",
            "to set the GPU flag to False.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/theano/tensor/nnet/conv.py:98: UserWarning: theano.tensor.nnet.conv.conv2d is deprecated. Use theano.tensor.nnet.conv2d instead.\n",
            "  warnings.warn(\"theano.tensor.nnet.conv.conv2d is deprecated.\"\n",
            "/content/nn3/src/network3.py:237: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
            "  pooled_out = pool_2d(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training mini-batch number 0\n",
            "Training mini-batch number 1000\n",
            "Training mini-batch number 2000\n",
            "Training mini-batch number 3000\n",
            "Training mini-batch number 4000\n",
            "Epoch 0: validation accuracy 0.9377000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9310000000000002\n",
            "Training mini-batch number 5000\n",
            "Training mini-batch number 6000\n",
            "Training mini-batch number 7000\n",
            "Training mini-batch number 8000\n",
            "Training mini-batch number 9000\n",
            "Epoch 1: validation accuracy 0.9609\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9558000000000001\n",
            "Training mini-batch number 10000\n",
            "Training mini-batch number 11000\n",
            "Training mini-batch number 12000\n",
            "Training mini-batch number 13000\n",
            "Training mini-batch number 14000\n",
            "Epoch 2: validation accuracy 0.9695\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9679000000000001\n",
            "Training mini-batch number 15000\n",
            "Training mini-batch number 16000\n",
            "Training mini-batch number 17000\n",
            "Training mini-batch number 18000\n",
            "Training mini-batch number 19000\n",
            "Epoch 3: validation accuracy 0.9751000000000002\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9735\n",
            "Training mini-batch number 20000\n",
            "Training mini-batch number 21000\n",
            "Training mini-batch number 22000\n",
            "Training mini-batch number 23000\n",
            "Training mini-batch number 24000\n",
            "Epoch 4: validation accuracy 0.977\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9760000000000001\n",
            "Training mini-batch number 25000\n",
            "Training mini-batch number 26000\n",
            "Training mini-batch number 27000\n",
            "Training mini-batch number 28000\n",
            "Training mini-batch number 29000\n",
            "Epoch 5: validation accuracy 0.9787\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9771\n",
            "Training mini-batch number 30000\n",
            "Training mini-batch number 31000\n",
            "Training mini-batch number 32000\n",
            "Training mini-batch number 33000\n",
            "Training mini-batch number 34000\n",
            "Epoch 6: validation accuracy 0.9796\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9786000000000001\n",
            "Training mini-batch number 35000\n",
            "Training mini-batch number 36000\n",
            "Training mini-batch number 37000\n",
            "Training mini-batch number 38000\n",
            "Training mini-batch number 39000\n",
            "Epoch 7: validation accuracy 0.9812000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9806\n",
            "Training mini-batch number 40000\n",
            "Training mini-batch number 41000\n",
            "Training mini-batch number 42000\n",
            "Training mini-batch number 43000\n",
            "Training mini-batch number 44000\n",
            "Epoch 8: validation accuracy 0.9831\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9815\n",
            "Training mini-batch number 45000\n",
            "Training mini-batch number 46000\n",
            "Training mini-batch number 47000\n",
            "Training mini-batch number 48000\n",
            "Training mini-batch number 49000\n",
            "Epoch 9: validation accuracy 0.9840000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9824\n",
            "Training mini-batch number 50000\n",
            "Training mini-batch number 51000\n",
            "Training mini-batch number 52000\n",
            "Training mini-batch number 53000\n",
            "Training mini-batch number 54000\n",
            "Epoch 10: validation accuracy 0.9848000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9835\n",
            "Training mini-batch number 55000\n",
            "Training mini-batch number 56000\n",
            "Training mini-batch number 57000\n",
            "Training mini-batch number 58000\n",
            "Training mini-batch number 59000\n",
            "Epoch 11: validation accuracy 0.9853000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9844\n",
            "Training mini-batch number 60000\n",
            "Training mini-batch number 61000\n",
            "Training mini-batch number 62000\n",
            "Training mini-batch number 63000\n",
            "Training mini-batch number 64000\n",
            "Epoch 12: validation accuracy 0.9855\n",
            "This is the best validation accuracy to date.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-57962ce63f17>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mFullyConnectedLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n\u001b[0;32m---> 15\u001b[0;31m net.SGD(training_data, 60, mini_batch_size, 0.1, \n\u001b[0m\u001b[1;32m     16\u001b[0m             validation_data, test_data)   \n\u001b[1;32m     17\u001b[0m \u001b[0mfinish\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/nn3/src/network3.py\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(self, training_data, epochs, mini_batch_size, eta, validation_data, test_data, lmbda)\u001b[0m\n\u001b[1;32m    181\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                             test_accuracy = np.mean(\n\u001b[0;32m--> 183\u001b[0;31m                                 [test_mb_accuracy(j) for j in range(num_test_batches)])\n\u001b[0m\u001b[1;32m    184\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'The corresponding test accuracy is {test_accuracy}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished training network.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/nn3/src/network3.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    181\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                             test_accuracy = np.mean(\n\u001b[0;32m--> 183\u001b[0;31m                                 [test_mb_accuracy(j) for j in range(num_test_batches)])\n\u001b[0m\u001b[1;32m    184\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'The corresponding test accuracy is {test_accuracy}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished training network.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python expand_mnist.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irPwLqoFMAR9",
        "outputId": "e8659bc9-3cc4-4b9f-96d9-3ae37a949370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expanding the MNIST training set\n",
            "Expanding image number 1000\n",
            "Expanding image number 2000\n",
            "Expanding image number 3000\n",
            "Expanding image number 4000\n",
            "Expanding image number 5000\n",
            "Expanding image number 6000\n",
            "Expanding image number 7000\n",
            "Expanding image number 8000\n",
            "Expanding image number 9000\n",
            "Expanding image number 10000\n",
            "Expanding image number 11000\n",
            "Expanding image number 12000\n",
            "Expanding image number 13000\n",
            "Expanding image number 14000\n",
            "Expanding image number 15000\n",
            "Expanding image number 16000\n",
            "Expanding image number 17000\n",
            "Expanding image number 18000\n",
            "Expanding image number 19000\n",
            "Expanding image number 20000\n",
            "Expanding image number 21000\n",
            "Expanding image number 22000\n",
            "Expanding image number 23000\n",
            "Expanding image number 24000\n",
            "Expanding image number 25000\n",
            "Expanding image number 26000\n",
            "Expanding image number 27000\n",
            "Expanding image number 28000\n",
            "Expanding image number 29000\n",
            "Expanding image number 30000\n",
            "Expanding image number 31000\n",
            "Expanding image number 32000\n",
            "Expanding image number 33000\n",
            "Expanding image number 34000\n",
            "Expanding image number 35000\n",
            "Expanding image number 36000\n",
            "Expanding image number 37000\n",
            "Expanding image number 38000\n",
            "Expanding image number 39000\n",
            "Expanding image number 40000\n",
            "Expanding image number 41000\n",
            "Expanding image number 42000\n",
            "Expanding image number 43000\n",
            "Expanding image number 44000\n",
            "Expanding image number 45000\n",
            "Expanding image number 46000\n",
            "Expanding image number 47000\n",
            "Expanding image number 48000\n",
            "Expanding image number 49000\n",
            "Expanding image number 50000\n",
            "Saving expanded data. This may take a few minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import network3\n",
        "from network3 import Network\n",
        "from network3 import ConvPoolLayer, FullyConnectedLayer, SoftmaxLayer\n",
        "from network3 import ReLU\n",
        "training_data, validation_data, test_data = network3.load_data_shared()\n",
        "mini_batch_size = 10\n",
        "\n",
        "start = time.time()\n",
        "expanded_training_data, _, _ = network3.load_data_shared(\"../data/mnist_expanded.pkl.gz\")\n",
        "net = Network([\n",
        "        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
        "                      filter_shape=(20, 1, 5, 5), \n",
        "                      poolsize=(2, 2), \n",
        "                      activation_fn=ReLU),\n",
        "        ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), \n",
        "                      filter_shape=(40, 20, 5, 5), \n",
        "                      poolsize=(2, 2), \n",
        "                      activation_fn=ReLU),\n",
        "        FullyConnectedLayer(n_in=40*4*4, n_out=100, activation_fn=ReLU),\n",
        "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
        "net.SGD(expanded_training_data, 60, mini_batch_size, 0.03, \n",
        "            validation_data, test_data, lmbda=0.1)\n",
        "finish = time.time()\n",
        "elapsed = finish-start\n",
        "print(elapsed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VD0PY5UxMOSn",
        "outputId": "00bc7876-ffbc-46f0-bf99-23288c18c576"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/theano/tensor/nnet/conv.py:98: UserWarning: theano.tensor.nnet.conv.conv2d is deprecated. Use theano.tensor.nnet.conv2d instead.\n",
            "  warnings.warn(\"theano.tensor.nnet.conv.conv2d is deprecated.\"\n",
            "/content/nn3/src/network3.py:237: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
            "  pooled_out = pool_2d(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training mini-batch number 0\n",
            "Training mini-batch number 1000\n",
            "Training mini-batch number 2000\n",
            "Training mini-batch number 3000\n",
            "Training mini-batch number 4000\n",
            "Training mini-batch number 5000\n",
            "Training mini-batch number 6000\n",
            "Training mini-batch number 7000\n",
            "Training mini-batch number 8000\n",
            "Training mini-batch number 9000\n",
            "Training mini-batch number 10000\n",
            "Training mini-batch number 11000\n",
            "Training mini-batch number 12000\n",
            "Training mini-batch number 13000\n",
            "Training mini-batch number 14000\n",
            "Training mini-batch number 15000\n",
            "Training mini-batch number 16000\n",
            "Training mini-batch number 17000\n",
            "Training mini-batch number 18000\n",
            "Training mini-batch number 19000\n",
            "Training mini-batch number 20000\n",
            "Training mini-batch number 21000\n",
            "Training mini-batch number 22000\n",
            "Training mini-batch number 23000\n",
            "Training mini-batch number 24000\n",
            "Epoch 0: validation accuracy 0.9887\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9892000000000001\n",
            "Training mini-batch number 25000\n",
            "Training mini-batch number 26000\n",
            "Training mini-batch number 27000\n",
            "Training mini-batch number 28000\n",
            "Training mini-batch number 29000\n",
            "Training mini-batch number 30000\n",
            "Training mini-batch number 31000\n",
            "Training mini-batch number 32000\n",
            "Training mini-batch number 33000\n",
            "Training mini-batch number 34000\n",
            "Training mini-batch number 35000\n",
            "Training mini-batch number 36000\n",
            "Training mini-batch number 37000\n",
            "Training mini-batch number 38000\n",
            "Training mini-batch number 39000\n",
            "Training mini-batch number 40000\n",
            "Training mini-batch number 41000\n",
            "Training mini-batch number 42000\n",
            "Training mini-batch number 43000\n",
            "Training mini-batch number 44000\n",
            "Training mini-batch number 45000\n",
            "Training mini-batch number 46000\n",
            "Training mini-batch number 47000\n",
            "Training mini-batch number 48000\n",
            "Training mini-batch number 49000\n",
            "Epoch 1: validation accuracy 0.9899000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9907\n",
            "Training mini-batch number 50000\n",
            "Training mini-batch number 51000\n",
            "Training mini-batch number 52000\n",
            "Training mini-batch number 53000\n",
            "Training mini-batch number 54000\n",
            "Training mini-batch number 55000\n",
            "Training mini-batch number 56000\n",
            "Training mini-batch number 57000\n",
            "Training mini-batch number 58000\n",
            "Training mini-batch number 59000\n",
            "Training mini-batch number 60000\n",
            "Training mini-batch number 61000\n",
            "Training mini-batch number 62000\n",
            "Training mini-batch number 63000\n",
            "Training mini-batch number 64000\n",
            "Training mini-batch number 65000\n",
            "Training mini-batch number 66000\n",
            "Training mini-batch number 67000\n",
            "Training mini-batch number 68000\n",
            "Training mini-batch number 69000\n",
            "Training mini-batch number 70000\n",
            "Training mini-batch number 71000\n",
            "Training mini-batch number 72000\n",
            "Training mini-batch number 73000\n",
            "Training mini-batch number 74000\n",
            "Epoch 2: validation accuracy 0.9899000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9897999999999999\n",
            "Training mini-batch number 75000\n",
            "Training mini-batch number 76000\n",
            "Training mini-batch number 77000\n",
            "Training mini-batch number 78000\n",
            "Training mini-batch number 79000\n",
            "Training mini-batch number 80000\n",
            "Training mini-batch number 81000\n",
            "Training mini-batch number 82000\n",
            "Training mini-batch number 83000\n",
            "Training mini-batch number 84000\n",
            "Training mini-batch number 85000\n",
            "Training mini-batch number 86000\n",
            "Training mini-batch number 87000\n",
            "Training mini-batch number 88000\n",
            "Training mini-batch number 89000\n",
            "Training mini-batch number 90000\n",
            "Training mini-batch number 91000\n",
            "Training mini-batch number 92000\n",
            "Training mini-batch number 93000\n",
            "Training mini-batch number 94000\n",
            "Training mini-batch number 95000\n",
            "Training mini-batch number 96000\n",
            "Training mini-batch number 97000\n",
            "Training mini-batch number 98000\n",
            "Training mini-batch number 99000\n",
            "Epoch 3: validation accuracy 0.9908\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.991\n",
            "Training mini-batch number 100000\n",
            "Training mini-batch number 101000\n",
            "Training mini-batch number 102000\n",
            "Training mini-batch number 103000\n",
            "Training mini-batch number 104000\n",
            "Training mini-batch number 105000\n",
            "Training mini-batch number 106000\n",
            "Training mini-batch number 107000\n",
            "Training mini-batch number 108000\n",
            "Training mini-batch number 109000\n",
            "Training mini-batch number 110000\n",
            "Training mini-batch number 111000\n",
            "Training mini-batch number 112000\n",
            "Training mini-batch number 113000\n",
            "Training mini-batch number 114000\n",
            "Training mini-batch number 115000\n",
            "Training mini-batch number 116000\n",
            "Training mini-batch number 117000\n",
            "Training mini-batch number 118000\n",
            "Training mini-batch number 119000\n",
            "Training mini-batch number 120000\n",
            "Training mini-batch number 121000\n",
            "Training mini-batch number 122000\n",
            "Training mini-batch number 123000\n",
            "Training mini-batch number 124000\n",
            "Epoch 4: validation accuracy 0.9912000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9924000000000001\n",
            "Training mini-batch number 125000\n",
            "Training mini-batch number 126000\n",
            "Training mini-batch number 127000\n",
            "Training mini-batch number 128000\n",
            "Training mini-batch number 129000\n",
            "Training mini-batch number 130000\n",
            "Training mini-batch number 131000\n",
            "Training mini-batch number 132000\n",
            "Training mini-batch number 133000\n",
            "Training mini-batch number 134000\n",
            "Training mini-batch number 135000\n",
            "Training mini-batch number 136000\n",
            "Training mini-batch number 137000\n",
            "Training mini-batch number 138000\n",
            "Training mini-batch number 139000\n",
            "Training mini-batch number 140000\n",
            "Training mini-batch number 141000\n",
            "Training mini-batch number 142000\n",
            "Training mini-batch number 143000\n",
            "Training mini-batch number 144000\n",
            "Training mini-batch number 145000\n",
            "Training mini-batch number 146000\n",
            "Training mini-batch number 147000\n",
            "Training mini-batch number 148000\n",
            "Training mini-batch number 149000\n",
            "Epoch 5: validation accuracy 0.9906\n",
            "Training mini-batch number 150000\n",
            "Training mini-batch number 151000\n",
            "Training mini-batch number 152000\n",
            "Training mini-batch number 153000\n",
            "Training mini-batch number 154000\n",
            "Training mini-batch number 155000\n",
            "Training mini-batch number 156000\n",
            "Training mini-batch number 157000\n",
            "Training mini-batch number 158000\n",
            "Training mini-batch number 159000\n",
            "Training mini-batch number 160000\n",
            "Training mini-batch number 161000\n",
            "Training mini-batch number 162000\n",
            "Training mini-batch number 163000\n",
            "Training mini-batch number 164000\n",
            "Training mini-batch number 165000\n",
            "Training mini-batch number 166000\n",
            "Training mini-batch number 167000\n",
            "Training mini-batch number 168000\n",
            "Training mini-batch number 169000\n",
            "Training mini-batch number 170000\n",
            "Training mini-batch number 171000\n",
            "Training mini-batch number 172000\n",
            "Training mini-batch number 173000\n",
            "Training mini-batch number 174000\n",
            "Epoch 6: validation accuracy 0.9923\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9919000000000001\n",
            "Training mini-batch number 175000\n",
            "Training mini-batch number 176000\n",
            "Training mini-batch number 177000\n",
            "Training mini-batch number 178000\n",
            "Training mini-batch number 179000\n",
            "Training mini-batch number 180000\n",
            "Training mini-batch number 181000\n",
            "Training mini-batch number 182000\n",
            "Training mini-batch number 183000\n",
            "Training mini-batch number 184000\n",
            "Training mini-batch number 185000\n",
            "Training mini-batch number 186000\n",
            "Training mini-batch number 187000\n",
            "Training mini-batch number 188000\n",
            "Training mini-batch number 189000\n",
            "Training mini-batch number 190000\n",
            "Training mini-batch number 191000\n",
            "Training mini-batch number 192000\n",
            "Training mini-batch number 193000\n",
            "Training mini-batch number 194000\n",
            "Training mini-batch number 195000\n",
            "Training mini-batch number 196000\n",
            "Training mini-batch number 197000\n",
            "Training mini-batch number 198000\n",
            "Training mini-batch number 199000\n",
            "Epoch 7: validation accuracy 0.9914000000000001\n",
            "Training mini-batch number 200000\n",
            "Training mini-batch number 201000\n",
            "Training mini-batch number 202000\n",
            "Training mini-batch number 203000\n",
            "Training mini-batch number 204000\n",
            "Training mini-batch number 205000\n",
            "Training mini-batch number 206000\n",
            "Training mini-batch number 207000\n",
            "Training mini-batch number 208000\n",
            "Training mini-batch number 209000\n",
            "Training mini-batch number 210000\n",
            "Training mini-batch number 211000\n",
            "Training mini-batch number 212000\n",
            "Training mini-batch number 213000\n",
            "Training mini-batch number 214000\n",
            "Training mini-batch number 215000\n",
            "Training mini-batch number 216000\n",
            "Training mini-batch number 217000\n",
            "Training mini-batch number 218000\n",
            "Training mini-batch number 219000\n",
            "Training mini-batch number 220000\n",
            "Training mini-batch number 221000\n",
            "Training mini-batch number 222000\n",
            "Training mini-batch number 223000\n",
            "Training mini-batch number 224000\n",
            "Epoch 8: validation accuracy 0.9924000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9933000000000001\n",
            "Training mini-batch number 225000\n",
            "Training mini-batch number 226000\n",
            "Training mini-batch number 227000\n",
            "Training mini-batch number 228000\n",
            "Training mini-batch number 229000\n",
            "Training mini-batch number 230000\n",
            "Training mini-batch number 231000\n",
            "Training mini-batch number 232000\n",
            "Training mini-batch number 233000\n",
            "Training mini-batch number 234000\n",
            "Training mini-batch number 235000\n",
            "Training mini-batch number 236000\n",
            "Training mini-batch number 237000\n",
            "Training mini-batch number 238000\n",
            "Training mini-batch number 239000\n",
            "Training mini-batch number 240000\n",
            "Training mini-batch number 241000\n",
            "Training mini-batch number 242000\n",
            "Training mini-batch number 243000\n",
            "Training mini-batch number 244000\n",
            "Training mini-batch number 245000\n",
            "Training mini-batch number 246000\n",
            "Training mini-batch number 247000\n",
            "Training mini-batch number 248000\n",
            "Training mini-batch number 249000\n",
            "Epoch 9: validation accuracy 0.9926\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9926\n",
            "Training mini-batch number 250000\n",
            "Training mini-batch number 251000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9db912eb3438>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mFullyConnectedLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n\u001b[0;32m---> 22\u001b[0;31m net.SGD(expanded_training_data, 60, mini_batch_size, 0.03, \n\u001b[0m\u001b[1;32m     23\u001b[0m             validation_data, test_data, lmbda=0.1)\n\u001b[1;32m     24\u001b[0m \u001b[0mfinish\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/nn3/src/network3.py\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(self, training_data, epochs, mini_batch_size, eta, validation_data, test_data, lmbda)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training mini-batch number {iteration}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                 \u001b[0mcost_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_mb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnum_training_batches\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                     validation_accuracy = np.mean(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 2"
      ],
      "metadata": {
        "id": "U2ZHfCDU4ZoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing code from part 2 starting point\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import keras.datasets.mnist as kdm\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = kdm.load_data()\n",
        "assert x_train.shape == (60000, 28, 28)\n",
        "assert x_test.shape == (10000, 28, 28)\n",
        "assert y_train.shape == (60000,)\n",
        "assert y_test.shape == (10000,)\n",
        "\n",
        "print(\"before converting...\", y_train[0])\n",
        "\n",
        "# reshape\n",
        "img_rows, img_cols = 28, 28\n",
        "# normalize inputs to between 0 and 1\n",
        "import numpy as np\n",
        "x_train = np.true_divide(x_train, 255)\n",
        "x_test = np.true_divide(x_test, 255)\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "print(y_test[0])\n",
        "\n",
        "# convert to vector outputs \n",
        "num_classes = 10\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "print(\"after converting y...\", y_test[0])"
      ],
      "metadata": {
        "id": "_LEMiIht5Z6X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e5e1ad9-1fb7-4738-ac60-37845bfa2bb1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before converting... 5\n",
            "7\n",
            "after converting y... [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KfX9xx6pE3cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Hi76OiM6hyY2",
        "outputId": "4eb8ecac-418a-4d04-c9fa-4225b311686f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "6000/6000 [==============================] - 54s 9ms/step - loss: 0.1484 - accuracy: 0.9543 - val_loss: 0.0479 - val_accuracy: 0.9846\n",
            "Epoch 2/30\n",
            "6000/6000 [==============================] - 54s 9ms/step - loss: 0.0475 - accuracy: 0.9856 - val_loss: 0.0359 - val_accuracy: 0.9883\n",
            "Epoch 3/30\n",
            "6000/6000 [==============================] - 52s 9ms/step - loss: 0.0327 - accuracy: 0.9896 - val_loss: 0.0292 - val_accuracy: 0.9907\n",
            "Epoch 4/30\n",
            "6000/6000 [==============================] - 51s 9ms/step - loss: 0.0242 - accuracy: 0.9925 - val_loss: 0.0294 - val_accuracy: 0.9904\n",
            "Epoch 5/30\n",
            "6000/6000 [==============================] - 53s 9ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.0263 - val_accuracy: 0.9925\n",
            "Epoch 6/30\n",
            "6000/6000 [==============================] - 54s 9ms/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.0231 - val_accuracy: 0.9922\n",
            "Epoch 7/30\n",
            "6000/6000 [==============================] - 54s 9ms/step - loss: 0.0092 - accuracy: 0.9975 - val_loss: 0.0248 - val_accuracy: 0.9919\n",
            "Epoch 8/30\n",
            "6000/6000 [==============================] - 52s 9ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.0240 - val_accuracy: 0.9925\n",
            "Epoch 9/30\n",
            "6000/6000 [==============================] - 53s 9ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.0225 - val_accuracy: 0.9931\n",
            "Epoch 10/30\n",
            "6000/6000 [==============================] - 52s 9ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0221 - val_accuracy: 0.9931\n",
            "Epoch 11/30\n",
            "6000/6000 [==============================] - 52s 9ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0231 - val_accuracy: 0.9931\n",
            "Epoch 12/30\n",
            "6000/6000 [==============================] - 54s 9ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0212 - val_accuracy: 0.9934\n",
            "Epoch 13/30\n",
            "6000/6000 [==============================] - 53s 9ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0215 - val_accuracy: 0.9932\n",
            "Epoch 14/30\n",
            "6000/6000 [==============================] - 55s 9ms/step - loss: 9.8174e-04 - accuracy: 0.9999 - val_loss: 0.0214 - val_accuracy: 0.9940\n",
            "Epoch 15/30\n",
            "6000/6000 [==============================] - 55s 9ms/step - loss: 8.5295e-04 - accuracy: 0.9999 - val_loss: 0.0213 - val_accuracy: 0.9935\n",
            "Epoch 16/30\n",
            "6000/6000 [==============================] - 55s 9ms/step - loss: 7.5464e-04 - accuracy: 0.9999 - val_loss: 0.0217 - val_accuracy: 0.9937\n",
            "Epoch 17/30\n",
            "6000/6000 [==============================] - 52s 9ms/step - loss: 6.8457e-04 - accuracy: 0.9999 - val_loss: 0.0220 - val_accuracy: 0.9935\n",
            "Epoch 18/30\n",
            "6000/6000 [==============================] - 54s 9ms/step - loss: 6.2970e-04 - accuracy: 0.9999 - val_loss: 0.0223 - val_accuracy: 0.9936\n",
            "Epoch 19/30\n",
            "6000/6000 [==============================] - 54s 9ms/step - loss: 5.8001e-04 - accuracy: 0.9999 - val_loss: 0.0221 - val_accuracy: 0.9937\n",
            "Epoch 20/30\n",
            "6000/6000 [==============================] - 52s 9ms/step - loss: 5.3537e-04 - accuracy: 0.9999 - val_loss: 0.0222 - val_accuracy: 0.9936\n",
            "Epoch 21/30\n",
            "5177/6000 [========================>.....] - ETA: 6s - loss: 5.2808e-04 - accuracy: 0.9999"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d7799b5af31f>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m model.fit(x_train, y_train,\n\u001b[0m\u001b[1;32m     19\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "#model for part 2 from assignment instructions\n",
        "model = keras.models.Sequential([\n",
        "  layers.Conv2D(20, kernel_size=(5,5), activation='relu', input_shape=(28,28,1)),\n",
        "  layers.MaxPool2D(pool_size=(2,2)),\n",
        "  layers.Conv2D(40, kernel_size=(5,5), activation='relu', input_shape=(20,12,12)),\n",
        "  layers.MaxPool2D(pool_size=(2,2)),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(100, activation='sigmoid'),\n",
        "  layers.Dense(10, activation='softmax')\n",
        "\n",
        "\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.SGD(learning_rate=0.1),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=10,\n",
        "          epochs=20,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ]
    }
  ]
}